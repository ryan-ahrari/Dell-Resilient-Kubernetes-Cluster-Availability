#----------------------------------------------------------------------------------
# Infinte for loop, only will break in DR (Disaster Recovery) scenario


    #----------------------------------------------------------------------------------
    # inital etcd health check section
        # ping each node to see if it is responsive in a short time frame (<2s)
            # if no response from leader node, there is unstability in cluster
                # call restabilization function
            # if no response from extra nodes
                # write, or append error message to etcd_failure_error.txt
                # based on error message, call appropriate error function          
    #----------------------------------------------------------------------------------


    #----------------------------------------------------------------------------------
    # error n (if n < [1/2 cluster size]) nodes down 
        # find number of potential members (m) in cluster
        # find all domains (d) and racks of cluster (r)
            # if n<m
                # call instance placing function(d, r, n) 
            # if n>m
                # on m do the following
                    # call instance placing function(d, r, m)
                # join 2*(n-m) new members to cluster
                    # call instance placing function(d, r, n-m)             
    #----------------------------------------------------------------------------------


    #----------------------------------------------------------------------------------
    # instance placing function with domain number d, rack number r, and n instances
        # from 0 to d domains
                    # from 0 to r racks
                        # place n/(d*r) instances of etcd on members
    #----------------------------------------------------------------------------------


    #----------------------------------------------------------------------------------
    # restabilization function, etcd leader unresponsive
        # ping all nodes again and record fastest responder
            # make fastest responding node new etcd leader 
                # update leader information where necessary so all nodes can point to leader
                    # return to beginning and redo error check
    #----------------------------------------------------------------------------------
    

    #----------------------------------------------------------------------------------
    # error more than 1/2 cluster nodes down
        # DR scenario
            # every 1 sec check if DR has completed 
                # when DR done do next health check
    #----------------------------------------------------------------------------------


    #----------------------------------------------------------------------------------
    # confirmation of health check script
        # if all nodes now healthy
            # wait 5 seconds before going through script again
        # else immediately rerun script
    #----------------------------------------------------------------------------------


#----------------------------------------------------------------------------------
